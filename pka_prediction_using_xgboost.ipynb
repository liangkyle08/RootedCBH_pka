{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e71e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install xgboost\n",
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1560e04d-12eb-4cef-b4ad-57d390ef8948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.) imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "614c8518-1225-44e8-8047-62adbbb9cc40",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File Users\\liang\\OneDrive\\Documents\\GitHub\\RootedCBH_pka\\datasets\\train_split.csv does not exist: 'Users\\\\liang\\\\OneDrive\\\\Documents\\\\GitHub\\\\RootedCBH_pka\\\\datasets\\\\train_split.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-558032a77a67>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# load CSVs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mdf_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mdf_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rooted-cbh-env/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rooted-cbh-env/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rooted-cbh-env/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rooted-cbh-env/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rooted-cbh-env/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File Users\\liang\\OneDrive\\Documents\\GitHub\\RootedCBH_pka\\datasets\\train_split.csv does not exist: 'Users\\\\liang\\\\OneDrive\\\\Documents\\\\GitHub\\\\RootedCBH_pka\\\\datasets\\\\train_split.csv'"
     ]
    }
   ],
   "source": [
    "# 2.) load training and testing data\n",
    "\n",
    "# if you want to use this, replace this with where your data is\n",
    "train_path = \"Users\\liang\\OneDrive\\Documents\\GitHub\\RootedCBH_pka\\datasets\\\\train_split.csv\"\n",
    "\n",
    "test_path =\"Users\\liang\\OneDrive\\Documents\\GitHub\\RootedCBH_pka\\datasets\\\\test_split.csv\"\n",
    "\n",
    "# load CSVs\n",
    "df_train = pd.read_csv(train_path)\n",
    "df_test = pd.read_csv(test_path)\n",
    "\n",
    "# drop 'file' and 'predicted_rf (pKa)' if they exist\n",
    "df_train = df_train.drop(columns=[\"file\"], errors=\"ignore\").dropna()\n",
    "df_test = df_test.drop(columns=[\"file\", \"predicted_rf (pKa)\"], errors=\"ignore\").dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4ef492-3459-404f-9ba9-ed495d403f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 3.) set target and split into features and labels\n",
    "\n",
    "target = \"exp_pKa (pKa)\"  # we want get close to this (basically the control)\n",
    "\n",
    "X_train = df_train.drop(columns=[target])\n",
    "y_train = df_train[target]\n",
    "\n",
    "X_test = df_test.drop(columns=[target])\n",
    "y_test = df_test[target]\n",
    "evalset = [(X_train, y_train), (X_test,y_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7af8bc5-3d2c-461b-8a89-c2b125ff37ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.) Filter numeric features and align columns\n",
    "\n",
    "# keep only numeric columns\n",
    "X_train = X_train.select_dtypes(include=[\"number\"])\n",
    "X_test = X_test.select_dtypes(include=[\"number\"])\n",
    "\n",
    "# align test columns to match train (drop any extra or missing ones)\n",
    "X_test = X_test[X_train.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85a2ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterGrid, cross_val_score\n",
    "from xgboost import XGBRegressor\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "# Parameter grid\n",
    "param_grid = {\n",
    "    \"n_estimators\": [100, 200],\n",
    "    \"learning_rate\": [0.01, 0.1],\n",
    "    \"max_depth\": [3, 5, 7],\n",
    "    \"subsample\": [0.8, 1.0],\n",
    "    \"colsample_bytree\": [0.8, 1.0]\n",
    "}\n",
    "\n",
    "# List of all combinations\n",
    "all_params = list(ParameterGrid(param_grid))\n",
    "\n",
    "best_score = -np.inf\n",
    "best_model = None\n",
    "best_params = None\n",
    "\n",
    "# Progress bar over all parameter combinations\n",
    "for params in tqdm(all_params, desc=\"Grid search\"):\n",
    "    model = XGBRegressor(random_state=42, **params)\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "    mean_score = scores.mean()\n",
    "    \n",
    "    if mean_score > best_score:\n",
    "        best_score = mean_score\n",
    "        best_params = params\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbf4bbe-b985-4185-8a23-57b1f661182a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ~~~ OLD CODE WITHOUT PROGRESS BAR ~~~\n",
    "\"\"\"from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    \"n_estimators\": [100, 200],\n",
    "    \"learning_rate\": [0.01, 0.1],\n",
    "    \"max_depth\": [3, 5, 7],\n",
    "    \"subsample\": [0.8, 1.0],\n",
    "    \"colsample_bytree\": [0.8, 1.0]\n",
    "}\n",
    "\n",
    "# Set up model and grid search\n",
    "base_model = XGBRegressor(random_state=42)\n",
    "grid_search = GridSearchCV(base_model, param_grid, cv=5, scoring='neg_mean_squared_error', verbose=1, n_jobs=-1)\n",
    "\n",
    "# Fit to training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best model\n",
    "model = grid_search.best_estimator_\n",
    "\n",
    "# Predict using the tuned model\n",
    "y_pred = model.predict(X_test)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02baa699",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train Best Model\n",
    "best_model = XGBRegressor(random_state=42, **best_params)\n",
    "best_model.fit(X_train, y_train,eval_metric='logloss', eval_set = evalset)\n",
    "y_pred = best_model.predict(X_test)\n",
    "yhat = model.predict(X_test)\n",
    "score = accuracy_score(y_test, yhat)\n",
    "print('Accuracy: %.3f' % score)\n",
    "# retrieve performance metrics\n",
    "results = model.evals_result()\n",
    "# plot learning curves\n",
    "pyplot.plot(results['validation_0']['logloss'], label='train')\n",
    "pyplot.plot(results['validation_1']['logloss'], label='test')\n",
    "# show the legend\n",
    "pyplot.legend()\n",
    "# show the plot\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acdc940-1012-4cfd-9512-8dd129756d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the test1 ML(RDKit + RootedCBH + QM)\n",
    "\n",
    "#rmse = mean_squared_error(y_test, y_pred, squared=False) doesnt work :(\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = mse ** 0.5\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
    "print(f\"MAE: {mae:.4f}\")\n",
    "# Plot predicted vs actual\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(y_test, y_pred, alpha=0.6, edgecolors=\"k\")\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], \"r--\")\n",
    "plt.xlabel(\"Actual pKa\")\n",
    "plt.ylabel(\"Predicted pKa\")\n",
    "plt.title(\"XGBoost: Predicted vs Actual pKa\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9ef382-93d3-4456-8e76-1024382b679a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === TRAINING AND TEST RMSE vs EPOCH PLOT ===\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "eval_result = {}\n",
    "model = XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    eval_set=[(X_train, y_train), (X_test, y_test)],\n",
    "    eval_metric=\"rmse\",\n",
    "    verbose=False,\n",
    "    evals_result=eval_result\n",
    ")\n",
    "\n",
    "\n",
    "# Plot train/test RMSE over epochs\n",
    "epochs = range(len(eval_result['validation_0']['rmse']))\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(epochs, eval_result['validation_0']['rmse'], label=\"Train RMSE\")\n",
    "plt.plot(epochs, eval_result['validation_1']['rmse'], label=\"Test RMSE\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.title(\"Training and Test RMSE vs. Epoch\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# === SPIDER PLOT FOR FUNCTIONAL GROUP MAE ===\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Define your functional group columns (replace with real ones)\n",
    "functional_groups = ['has_OH', 'has_NH2', 'has_COOH']  # Example only!\n",
    "\n",
    "group_errors = []\n",
    "labels_found = []\n",
    "\n",
    "for fg in functional_groups:\n",
    "    if fg in X_test.columns:\n",
    "        mask = X_test[fg] == 1\n",
    "        if mask.sum() > 0:\n",
    "            group_mae = mean_absolute_error(y_test[mask], y_pred[mask])\n",
    "            group_errors.append(group_mae)\n",
    "            labels_found.append(fg)\n",
    "\n",
    "# Radar chart\n",
    "stats = np.array(group_errors)\n",
    "labels = np.array(labels_found)\n",
    "angles = np.linspace(0, 2 * np.pi, len(labels), endpoint=False).tolist()\n",
    "stats = np.concatenate((stats, [stats[0]]))  # close loop\n",
    "angles += angles[:1]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 6), subplot_kw=dict(polar=True))\n",
    "ax.plot(angles, stats, marker='o', label='MAE per group')\n",
    "ax.fill(angles, stats, alpha=0.25)\n",
    "ax.set_thetagrids(np.degrees(angles[:-1]), labels)\n",
    "ax.set_title(\"Spider Plot: Functional Group MAE\")\n",
    "ax.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd1cbcc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
